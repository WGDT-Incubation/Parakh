import streamlit as st
import numpy as np
from PIL import Image, ImageChops, ImageEnhance
import cv2
from pdf2image import convert_from_path
import tempfile

st.set_page_config(page_title="AI Forgery Detection (Single Document)", layout="wide")

st.title("üïµÔ∏è‚Äç‚ôÇÔ∏è CAG Parakh ‚Äî Detect Edited or Fake Document Images")
st.caption("Detect if a single document image (like PAN, ID, bill, form) has been digitally edited or tampered using AI-based image forensics.")

# ---------- Utility Functions ----------

def convert_pdf_to_image(uploaded_pdf):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_pdf.read())
        tmp.flush()
        images = convert_from_path(tmp.name)
    return images[0]

def perform_ela(image, quality=90):
    """Perform Error Level Analysis"""
    image = image.convert("RGB")
    temp_filename = "temp_ela.jpg"
    image.save(temp_filename, 'JPEG', quality=quality)
    ela_image = Image.open(temp_filename)
    diff = ImageChops.difference(image, ela_image)
    extrema = diff.getextrema()
    max_diff = max([ex[1] for ex in extrema]) if extrema else 0
    scale = 255.0 / max_diff if max_diff != 0 else 1
    ela_image = ImageEnhance.Brightness(diff).enhance(scale)
    return ela_image

def generate_heatmap_overlay(original, ela_image, threshold=120, alpha=0.45):
    """Create heatmap overlay for edited regions"""
    ela_gray = cv2.cvtColor(np.array(ela_image), cv2.COLOR_RGB2GRAY)
    _, mask = cv2.threshold(ela_gray, threshold, 255, cv2.THRESH_BINARY)
    mask = cv2.GaussianBlur(mask, (7, 7), 0)
    heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    overlay = cv2.addWeighted(np.array(original), 1 - alpha, heatmap, alpha, 0)
    suspicious_pixels = np.count_nonzero(mask > 50)
    return Image.fromarray(overlay), suspicious_pixels

def edge_noise_analysis(image):
    """Calculate edge and noise consistency"""
    gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
    return float(cv2.Laplacian(gray, cv2.CV_64F).var())

def clone_patch_inconsistency(image):
    """Detect patch duplication (copy-paste regions)"""
    gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(gray, None)
    return len(keypoints)

def preprocess_image(uploaded_file):
    if uploaded_file.type == "application/pdf":
        image = convert_pdf_to_image(uploaded_file)
    else:
        image = Image.open(uploaded_file).convert("RGB")
    return image


# ---------- Streamlit UI ----------
uploaded_file = st.file_uploader("üìÅ Upload Document Image or PDF", type=["jpg", "jpeg", "png", "pdf"])

if uploaded_file:
    image = preprocess_image(uploaded_file)
    st.image(image, caption="Uploaded Document", use_container_width=True)

    st.subheader("üì∏ Found Edited Section")
    ela_img = perform_ela(image, quality=90)
    st.image(ela_img, caption="ELA Visualization (brighter = possible edits)", use_container_width=True)
    ela_array = np.array(ela_img)
    ela_mean = np.mean(ela_array)
    st.write(f"ELA Mean Intensity: **{ela_mean:.2f}**")

    st.subheader("üß© Edge / Noise Consistency")
    noise_score = edge_noise_analysis(image)
    st.write(f"Noise Variance: **{noise_score:.2f}**")

    st.subheader("üß¨ Clone / Patch Consistency")
    keypoint_count = clone_patch_inconsistency(image)
    st.write(f"Keypoint Features Detected: **{keypoint_count}**")

    st.subheader("üî• Heatmap")
    heatmap_img, suspicious_regions = generate_heatmap_overlay(image, ela_img, threshold=120, alpha=0.5)
    st.image(heatmap_img, caption="Suspicious Regions Highlighted", use_container_width=True)

       # ---------- Improved Confidence Scoring ----------
    st.subheader("‚öñÔ∏è Step 5: Final Confidence & Verdict")

    # --- Enhanced ELA metric: focus on strong local brightness (top 5%) ---
    ela_gray = cv2.cvtColor(np.array(ela_img), cv2.COLOR_RGB2GRAY)
    ela_sorted = np.sort(ela_gray.flatten())

    #top5_mean = np.mean(ela_sorted[int(len(ela_sorted) * 0.95):])  # top 5% brightest pixels
    #localized_ela_score = min(100, top5_mean * 1.2)  # amplify localized difference
    top1_mean = np.mean(ela_sorted[int(len(ela_sorted)*0.99):])   # top 1 % pixels
    localized_ela_score = min(100, top1_mean * 2.5)               # give it more weight


    # --- Noise / Edge / Clone Factors ---
    noise_factor = 100 - min(100, (noise_score / 6))         # smoother = suspicious
    #region_factor = min(70, suspicious_regions / 120)         # more bright region = suspicious
    region_factor = min(100, suspicious_regions / 60)   # was /120

    clone_factor = 100 - min(100, (keypoint_count / 15))      # low keypoints = suspicious texture

    # --- Combine weights ---
    confidence_score = np.clip(
        (localized_ela_score * 0.45) +
        (noise_factor * 0.25) +
        (region_factor * 0.2) +
        (clone_factor * 0.1),
        0, 100
    )

    # --- Verdict Threshold ---
    #verdict = "FORGED / EDITED" if confidence_score >= 40 else "GENUINE / UNTAMPERED"
    verdict = "FORGED / EDITED" if confidence_score >= 45 else "GENUINE / UNTAMPERED"

    # --- Display Result ---
    st.progress(confidence_score / 100)
    if verdict == "FORGED / EDITED":
        st.error(f"üö® Document appears **{verdict}** ‚Äî Confidence: {confidence_score:.1f}%")
        st.caption("Detected high ELA intensity in localized region ‚Üí likely digitally added or modified content.")
    else:
        st.success(f"‚úÖ Document appears **{verdict}**")
        st.caption("No major localized editing or tampering detected.")


    # Try following updated code as well when dont want aggressive result to avoid making large number of doc as forged
    '''# ---------- Final Tuned Confidence Scoring ----------
        st.subheader("‚öñÔ∏è Step 5: Final Confidence & Verdict (Balanced)")

        # Convert ELA image to grayscale
        ela_gray = cv2.cvtColor(np.array(ela_img), cv2.COLOR_RGB2GRAY)

        # 1Ô∏è‚É£ Core ELA statistics
        mean_intensity = np.mean(ela_gray)
        std_intensity = np.std(ela_gray)
        max_intensity = np.max(ela_gray)

        # 2Ô∏è‚É£ Localized brightness detection
        bright_mask = ela_gray > (mean_intensity + 0.6 * (max_intensity - mean_intensity))
        bright_ratio = np.sum(bright_mask) / bright_mask.size * 100  # % of bright pixels

        # 3Ô∏è‚É£ Contrast-driven suspicion
        contrast_score = std_intensity * 1.1

        # 4Ô∏è‚É£ Combined ELA suspicion before damping
        ela_score_raw = np.clip((bright_ratio * 1.6) + (contrast_score * 0.8), 0, 100)

        # 5Ô∏è‚É£ Genuine dampening logic
        # If bright spots are <1% of area ‚Üí likely camera noise
        if bright_ratio < 1.0:
            ela_score = ela_score_raw * 0.4
        # If ELA pattern is evenly spread (low std) ‚Üí genuine lighting, not edit
        elif std_intensity < 18:
            ela_score = ela_score_raw * 0.6
        else:
            ela_score = ela_score_raw

        # 6Ô∏è‚É£ Other forensic factors
        noise_factor = 100 - min(100, (noise_score / 6))           # low noise = suspicious
        region_factor = min(100, suspicious_regions / 80)          # larger edited area
        clone_factor = 100 - min(100, (keypoint_count / 15))       # texture repetition

        # 7Ô∏è‚É£ Weighted fusion
        confidence_score = np.clip(
            (ela_score * 0.55) + (noise_factor * 0.15) +
            (region_factor * 0.25) + (clone_factor * 0.05),
            0, 100
        )

        # 8Ô∏è‚É£ Adaptive verdict thresholds
        if bright_ratio < 0.8 and std_intensity < 18:
            verdict_threshold = 55   # more tolerant for genuine scans
        else:
            verdict_threshold = 40   # sensitive for clear edits

        verdict = "FORGED / EDITED" if confidence_score >= verdict_threshold else "GENUINE / UNTAMPERED"

        # 9Ô∏è‚É£ Display results
        st.progress(confidence_score / 100)
        if verdict == "FORGED / EDITED":
            st.error(f"üö® Document appears **{verdict}** ‚Äî Confidence: {confidence_score:.1f}%")
            st.caption("Localized bright ELA regions and abnormal contrast suggest digital alteration.")
        else:
            st.success(f"‚úÖ Document appears **{verdict}** ‚Äî Confidence: {confidence_score:.1f}%")
            st.caption("ELA pattern uniform ‚Äî no signs of tampering beyond normal scan compression.")
'''


    st.download_button(
        "üíæ Download Heatmap Image",
        data=heatmap_img.tobytes(),
        file_name="forgery_heatmap.png",
        mime="image/png"
    )
